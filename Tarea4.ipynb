{"cells":[{"cell_type":"markdown","metadata":{"id":"wETZypwn6LBN"},"source":["Pontificia Universidad Católica de Chile <br>\n","Departamento de Ciencia de la Computación <br>\n","IIC2433 - Minería de Datos\n","<br>\n","\n","<center>\n","    <h2> Tarea 4 </h2>\n","    <h1>   </h1>\n","    <p>\n","        Profesor Marcelo Mendoza<br>\n","        Segundo Semestre 2022<br>    \n","        Fecha de entrega: Viernes 4 de noviembre 23.59 horas\n","    </p>\n","    <br>\n","</center>\n","\n","<br>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"aIG30JYa6bZ4"},"source":["# Indicaciones\n","\n","Deberás entregar **SOLO** el archivo .ipynb en el buzón respectivo en canvas. \n","\n","**IMPORTANTE**: \n","- Se te dará puntaje tanto por código como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un código perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendrá el puntaje completo.\n","- El notebook debe tener todas las celdas de código ejecutadas. Cualquier notebook que no las tenga no podrá ser corregido.\n","- El carácter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultará en un 1,1 como nota de curso."]},{"cell_type":"markdown","metadata":{},"source":["# Librerías aceptadas:\n","- `Numpy`\n","- `Pandas`\n","- Cualquier librería para graficar\n","\n","Clases y funciones aceptadas de la librería `sklearn`:\n","- `train_test_split` y `StratifiedKFold` del módulo `model_selection`\n","- `PCA` del módulo `decomposition`\n","- `MLPClassifier` del módulo `neural_network`\n","- Toda funcíon del módulo `metrics`\n","- Clasificadores varios (solo para la parte del bonus)\n","\n","Librerías y funciones prohibidas:\n","- Cualquier otra función de `sklearn`\n","- *Cualquier otra librería que maneje y prediga datos* \n","\n","<br>\n","\n","---"]},{"cell_type":"markdown","metadata":{"id":"Ahwxwdl66xPM"},"source":["# Introducción\n","<p align=\"center\">\n","  <img src=\"https://play-lh.googleusercontent.com/E_kpq1HGn5WU2P4S2yu0BwrPEHqiA-VBh2R7qoIjPFXdNvKA0A-8zi0RzRslUtEOnUvA\" width=\"200\"/>\n","</p><br>\n","\n","Un equipo de desarrolladores se encuentra creado una aplicación que sea capaz de resolver problemas de matemáticas tan solo escaneando el ejercicio. Sin embargo, se han encontrado con un obstaculo: Ninguno de ellos sabe como hacer que la aplicación reconozca los caracteres de las fotografías. Es entonces cuando deciden contactarte a tí para que con tus avanzadas habilidades en *Machine Learning* puedas ayudarles con su problema.\n","\n","Tu trabajo en este equipo será construir un MLP (*Multi-Layer Perceptron*) que, dada una foto de un dígito, sea capaz de predecir a cual clase corresponde (i.e. cual es el dígito de la foto). El equipo te ha proporcionado un [dataset](https://www.kaggle.com/competitions/digit-recognizer/data?select=train.csv) con fotografias de números para que entrenes y pruebes tu red neuronal. Para probar la robustez de tu modelo, deberás someterlo a ciertos procedimientos que se especificarán más adelante."]},{"cell_type":"markdown","metadata":{"id":"tcbHxQVqW2TX"},"source":["# 0. Set Up"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"2Te7gXVlYmwi"},"outputs":[],"source":["# Para importar más librerias, hazlo en esta sección\n","import numpy as np\n","import pandas as pd\n","\n","from sklearn.model_selection import train_test_split, StratifiedKFold\n","\n","from sklearn.metrics import accuracy_score, confusion_matrix\n","\n","from sklearn.decomposition import PCA\n","\n","from sklearn.neural_network import MLPClassifier\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sn\n","\n","import time"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"JCGXvh5I0E6J"},"outputs":[],"source":["# Puedes cambiar esto para leer los datos como más te acomode\n","df_main = pd.read_csv(\"digits.csv\")"]},{"cell_type":"markdown","metadata":{"id":"dNJx3-JLbZ3V"},"source":["Cada imagen de un dígito corresponde a una matriz de 28x28 (784 pixeles). De esta manera:\n","\n","- `X`: Matriz de 42000 x 784. Las filas corresponden a imágenes de dígitos y las columnas corresponden a los pixeles de dicha imagen (con valores desde el 0 al 256)\n","- `y`: *Ground truth* (42000 elementos). Indica la clase a la que pertenece la fila (i.e. el dígito de la foto. Va desde el 0 hasta el 9)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e0NiK_Q4bOy_"},"outputs":[],"source":["# Dejar esto como está\n","y = df_main[\"label\"]\n","df_main.drop(columns=['label'], inplace=True)\n","X = df_main"]},{"cell_type":"markdown","metadata":{"id":"OfQZZx21s5cH"},"source":["# 1. Preguntas Teóricas (1 pt)"]},{"cell_type":"markdown","metadata":{"id":"QJYe-i3HtFkN"},"source":["### ¿Como \"aprende\" un MLP?¿Cuales son algunos de los hiperparámetros que recibe?¿Que se obtiene como resultado de este entrenamiento?\n","\n","**Respuesta:** \n","\n","Feedfoward\n","Backpropagation\n","Gradiente descendente"]},{"cell_type":"markdown","metadata":{"id":"bIejhDiftyRE"},"source":["### Si bien los MLP pueden ser muy poderosos a la hora de clasificar, tienen un problema que puede ser no menor relacionado con la función que busca minimizar, ¿Cuál ese ese problema?¿Que soluciones se te ocurren para solucionarlo?\n","**Respuesta:** \n","\n","Random weight initialization\n","Feature scaling?\n"]},{"cell_type":"markdown","metadata":{"id":"uDDKY8gQxr3x"},"source":["# 2. Pre-procesamiento de los datos (0.5 pt)"]},{"cell_type":"markdown","metadata":{"id":"zTLRDiATqruZ"},"source":["Divide el dataset original en *train* y *test*, dejando un 10% de los datos para este último. Asegurate de que las clases estén balanceadas en ambos conjuntos de datos. Puedes utilizar la función `train_test_split` de `sklearn.model_selection`"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"n9RFwNiMChmT"},"outputs":[{"name":"stdout","output_type":"stream","text":["X: (42000, 784) y: (42000,)\n","X_train: (37800, 784) y_train: (37800,)\n","X_test: (4200, 784) y_test: (4200,)\n"]}],"source":["# Realiza aquí la separación balanceada en train y test\n","print(\"X:\", X.shape, \"y:\",y.shape)\n","\n","\n","# Separamos el dataset en train y test\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=2433, stratify=y)\n","print(\"X_train:\", X_train.shape, \"y_train:\",y_train.shape)\n","\n","print(\"X_test:\", X_test.shape, \"y_test:\",y_test.shape)"]},{"cell_type":"markdown","metadata":{"id":"z1NoVtiYyE9C"},"source":["Una vez tengas los conjuntos de *train* y *test* deberás generar dos datasets:\n","- *raw*: Los datos \"crudos\" sin mayor preprocesamiento.\n","- *PCA*: Sobre los datos crudos, aplicar un PCA reteniendo un 95% de la varianza.\n","\n","Atención: Ten cuidado de hacer PCA solo y únicamente con los datos del training, ya que ambos sets deben funcionar de forma independiente (Piensa que a priori \"no sabemos nada\" de los datos de testing, por lo que no deben influir en el entrenamiento). Para la retención de la varianza podría serte util el atributo de `explained_variance_ratio_` de [PCA](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.PCA.html). Una vez se haya hecho fit del set de *train*, tranforma también los datos de *test*"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"du8_dQpTC3VC"},"outputs":[{"name":"stdout","output_type":"stream","text":["0.9483161584016628\n","0.9487707288061605\n","0.9492417365865183\n","0.9497192641320903\n","0.9501370681838223\n"]}],"source":["X_train_raw = X_train\n","X_test_raw = X_test\n","\n","x = 150\n","var = 0\n","while var < 0.95:\n","    pca = PCA(n_components=x, random_state= 2433)\n","    pca.fit(X_train)\n","    var = pca.explained_variance_ratio_.sum()\n","    print(var)\n","    x += 1"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["155\n"]}],"source":["print(x)"]},{"cell_type":"markdown","metadata":{},"source":["El número de componentes que mantiene un 95% de varianza es 155."]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["pca = PCA(n_components=155, random_state= 2433)\n","pca.fit(X_train)\n","\n","X_train_pca = pca.transform(X_train)\n","X_test_pca = pca.transform(X_test)"]},{"cell_type":"markdown","metadata":{"id":"uhQB1oUmvW_D"},"source":["# 3. Multi-Layer Perceptron (2 pts)"]},{"cell_type":"markdown","metadata":{"id":"Ud17Tv8_wb4J"},"source":["Olvidemos el set de *test* por un rato, ya que lo usaremos más adelante para probar el funcionamiento de nuestro clasificador con datos que nunca ha visto. \n","\n","En esta parte de la tarea deberás usar la implementación del [MLP](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html) de Sklearn para realiza una busqueda de hiperparámetros en ambos set de *train* (*raw* y *PCA*). Algunos de los que puedes cambiar son:\n","- `hidden_layer_sizes`: Cantidad de capas de la red y cuantas neuronas tiene cada una (por ejemplo la tupla `(20, 8)` indica dos capas, la primera de 20 nodos y la segunda de 8 nodos)\n","- `activation`: Función de activación\n","- `max_iter`: Cantidad máxima de iteraciones que puede hacer la red\n","- y cualquier otro que estimes conveniente\n","\n","Si quieres cambiar alguno de los parámetros que no se han visto en clases no olvides mencionarlo y explicar brevemente en que consiste. Las únicas restricciones a la hora de probar hiperparámetros son que el entrenamiento se haga con el set de *train* y que se deben usar al menos 3 capas ocultas.\n","\n","Para validar la elección de hiperparámetros, deberas hacer un *cross-validation* con 5 folds (para ambos dataset). Para cada una de las folds, deberás obtener la matriz de confusión (presta atención a los errores más comunes) y el accuracy $\\eta$. El accuracy final de la elección de hiperparámetros será el promedio de las 5 folds.\n","\n","En resumen, se debe hacer lo siguiente:\n","- Proponer combinaciones de hiperparámetros\n","- Para cada combinación, hacer cross-validation con 5-folds\n","- Obtener la matriz de confusión y el accuracy de cada fold\n","- Obtener el accuracy del MLP con esa configuración\n","\n","\\* *Podría serte útil la función [StratifiedKFold](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html#sklearn.model_selection.StratifiedKFold)*\n","\n","\\** *Quizás para más adelante te interese medir el tiempo de entrenamiento de ambos dataset*"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"DFArKAT_EcLi"},"outputs":[],"source":["classifiers = []\n","activation = [\"logistic\", \"tanh\", \"relu\"]\n","hidden_layer = [(10, 10, 10), (100, 100, 100), (50, 50, 50, 50)]\n","max_iter = [50, 100, 200, 400, 600]\n","learning_rate_i = [0.0001, 0.001, 0.005, 0.01]\n","for act in activation:\n","    for hl in hidden_layer:\n","        for iter in max_iter:\n","            for lr in learning_rate_i:\n","                model = MLPClassifier(activation=act, hidden_layer_sizes=hl, max_iter=iter, learning_rate_init=lr, random_state=2433)\n","                classifiers.append([model, [act, hl, iter]])\n","\n","skf = StratifiedKFold(n_splits=5, shuffle=True, random_state= 2433)"]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["TRAIN: [ 6996  7001  7010 ... 37797 37798 37799] TEST: [   0    1    2 ... 7934 7938 7939]\n","TRAIN: [    0     1     2 ... 37797 37798 37799] TEST: [ 6996  7001  7010 ... 15606 15615 15629]\n","TRAIN: [    0     1     2 ... 37797 37798 37799] TEST: [14653 14659 14663 ... 23534 23543 23551]\n","TRAIN: [    0     1     2 ... 37797 37798 37799] TEST: [22298 22300 22306 ... 30932 30938 30958]\n","TRAIN: [    0     1     2 ... 30932 30938 30958] TEST: [29992 29993 29995 ... 37797 37798 37799]\n","\n","TRAIN: [ 6996  7001  7010 ... 37797 37798 37799] TEST: [   0    1    2 ... 7934 7938 7939]\n","TRAIN: [    0     1     2 ... 37797 37798 37799] TEST: [ 6996  7001  7010 ... 15606 15615 15629]\n","TRAIN: [    0     1     2 ... 37797 37798 37799] TEST: [14653 14659 14663 ... 23534 23543 23551]\n","TRAIN: [    0     1     2 ... 37797 37798 37799] TEST: [22298 22300 22306 ... 30932 30938 30958]\n","TRAIN: [    0     1     2 ... 30932 30938 30958] TEST: [29992 29993 29995 ... 37797 37798 37799]\n"]}],"source":["for train_index, test_index in skf.split(X_train_raw, y_train):\n","    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n","print()\n","for train_index, test_index in skf.split(X_train_pca, y_train):\n","    print(\"TRAIN:\", train_index, \"TEST:\", test_index)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for model, params in classifiers:\n","    for train_index, test_index in skf.split(X_train_raw, y_train):\n","        x_train_fold, x_test_fold = X_train_raw[train_index], X_train_raw[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]\n","        model.fit(x_train_fold, y_train_fold)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["for model, params in classifiers:\n","    for train_index, test_index in skf.split(X_train_pca, y_train):\n","        x_train_fold, x_test_fold = X_train_pca[train_index], X_train_pca[test_index]\n","        y_train_fold, y_test_fold = y_train[train_index], y_train[test_index]"]},{"cell_type":"markdown","metadata":{"id":"qS2A6MxsPcPg"},"source":["# 4. Testing y Análisis de Resultados (1.5 pts)"]},{"cell_type":"markdown","metadata":{"id":"HJiuZEntPh1J"},"source":["Traigamos de vuelta los sets de test.\n","\n","Predice en tu mejor red neural las clases de los sets de *test* (*Raw* y *PCA*). La mejor red neuronal para cada dataset será aquel que de un mayor accuracy. Una vez entrenada, obten las siguientes métricas\n","- Matriz de confusión\n","- Accuracy\n","- Sensibilidad y Especificidad\n","\n","Visualiza la matriz de confusión, ¿Cuáles son los errores más frecuentes?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"I1laHEadKEnG"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"PBletnM6J-ju"},"source":["Además, para cada una de las 10 clases crea una visualización que ilustre los casos borde de la clasificación utilizando el método [predict_proba](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier.predict_proba). Los casos borde son de dos tipos: \n","- **I)** Cuando la clase es asignada correctamente, a pesar de que había alta probabilida de clasificar mal. (ej.: Un 3 se clasifica como un 3, pero había alta probabilidad de clasificar con un 8)\n","\n","- **II)** Cuando no se asigna la clase en cuestión, pero de forma correcta. Aun así, había alta probabilidad de clasificar con la clase en estudio (e.: Un 7 no se clasifica como un 3, pero había alta probabilidad de sí hacerlo).\n","\n","Para el primer caso analiza cuales eran las otras clasificaciones más probables (se recomienda histograma apilado), y para el segundo indica cual era la probabilidad de clasificar mal (se recomienda histograma)\n","\n","\\* *Puedes elegir libremente que se considera como \"alta probabilidad\"*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fiwdT37FKGtw"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"RKUjIQ0eMi3T"},"source":["# 5. Preguntas Finales (1 pt)\n"]},{"cell_type":"markdown","metadata":{"id":"92bhnAbKut3P"},"source":["### ¿Cuales fueron los errores más recurrentes de la red neuronal?¿A que creés que se debe?\n","\n","**Respuesta:**"]},{"cell_type":"markdown","metadata":{"id":"MBTfIMNqu3jB"},"source":["### ¿Notas alguna diferencia entre las ejecuciones de los dataset *Raw* y *PCA*?¿Cuales son?\n","\n","**Respuesta:**"]},{"cell_type":"markdown","metadata":{"id":"BwAUFMENwTNa"},"source":["### ¿Se ven indicios de *over-fitting*?\n","\n","**Respuesta:**"]},{"cell_type":"markdown","metadata":{"id":"lZmVHLG0Em7z"},"source":["# ⭐ Bonus\n","Esta tarea cuenta con un bonus al que podrás optar. Cabe recalcar que para optar a este beneficio la nota de tu tarea (sin bonus) debe ser igual o superior a 3,95 (sin considerar posibles descuentos).\n","\n","## Otros clasificadores (5 décimas)\n","Realiza un procedimiento similar al que hiciste en esta tarea con otro clasificador y explica como funciona. Este procedimiento será un poco más simplificado:\n","- No es necesario responder preguntas teóricas\n","- Trabaja únicamente con un dataset. Puedes hacer reducción de dimensionalidad si lo deseas\n","- El set de train debe ser un 10% de los datos originales. Se debe hacer cross-validation con 5 folds. No es necesario obtener métricas de cada fold, basta con obtener el accuracy final del clasificador\n","- Elige la mejor combinación de hiperparámetros, evalua el set de test, obtén la matriz de confusión y accuracy ¿Cual clasificador tuvo mejores resultados?¿MLP o este?"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oortipLSIDcK"},"outputs":[],"source":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.7.9 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.9"},"vscode":{"interpreter":{"hash":"3c3a384c40a9a981b2ee63266612c19629e9c787808185d34a92557e569d1c5f"}}},"nbformat":4,"nbformat_minor":0}
